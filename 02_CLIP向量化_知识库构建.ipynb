{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxzC9o4Y/I3CZhg16ZEQeM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "365a4d6b9a4a414f87a7742d19c6a2ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59b0b16eb92046878b3fa00e7e4e8bfc",
              "IPY_MODEL_f32fc92bb15547fea3d87d5bbfe66126",
              "IPY_MODEL_19b87267b5734d49869a97eec665ea42"
            ],
            "layout": "IPY_MODEL_55c4e12af789473c8ef61e305007ddf9"
          }
        },
        "59b0b16eb92046878b3fa00e7e4e8bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_597a23d6b73647a6a63b2b25f94754d9",
            "placeholder": "​",
            "style": "IPY_MODEL_d84f63a3c58b43ce8cb5cb4ea3caa435",
            "value": "Fetching 1 files: 100%"
          }
        },
        "f32fc92bb15547fea3d87d5bbfe66126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00020c7fd27944beadf6fe8f85232f48",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88b99099199f4e4eb5ffc57a0e1e26fb",
            "value": 1
          }
        },
        "19b87267b5734d49869a97eec665ea42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfd0b5c3ffd4454b8aec0bb74b066ec8",
            "placeholder": "​",
            "style": "IPY_MODEL_93d084695dca434bafa3d40793c2aa4f",
            "value": " 1/1 [00:00&lt;00:00, 55.28it/s]"
          }
        },
        "55c4e12af789473c8ef61e305007ddf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "597a23d6b73647a6a63b2b25f94754d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d84f63a3c58b43ce8cb5cb4ea3caa435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00020c7fd27944beadf6fe8f85232f48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88b99099199f4e4eb5ffc57a0e1e26fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfd0b5c3ffd4454b8aec0bb74b066ec8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93d084695dca434bafa3d40793c2aa4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xintong120/Front-End-Interview/blob/master/02_CLIP%E5%90%91%E9%87%8F%E5%8C%96_%E7%9F%A5%E8%AF%86%E5%BA%93%E6%9E%84%E5%BB%BA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 环境准备和依赖安装"
      ],
      "metadata": {
        "id": "FM0HabLcBMxb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMUauLpSBK_t",
        "outputId": "4270fc49-0d76-41fe-dd25-f2ad38a0a9df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.12/dist-packages (0.7.3)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n"
          ]
        }
      ],
      "source": [
        "# 安装必要的依赖\n",
        "!pip install transformers torch torchvision\n",
        "!pip install pillow numpy\n",
        "!pip install tqdm loguru\n",
        "!pip install faiss-cpu  # 可选：用于高效向量搜索"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from loguru import logger\n",
        "from typing import List,Dict,Any,Optional\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "import base64\n",
        "from io import BytesIO\n"
      ],
      "metadata": {
        "id": "MeOvbzcOBbGr"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive 挂载 (仅在 Colab 环境需要)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 设置 Drive 路径\n",
        "drive_root = Path('/content/drive/MyDrive')\n",
        "input_dir = drive_root / 'RAG_处理结果'  # 第一阶段的输出目录"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWuHFlEUDuWD",
        "outputId": "7298f469-1bce-4443-9216-dd3a202fc8ae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vUI6jjk0DtgO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 配置路径和参数"
      ],
      "metadata": {
        "id": "34ybP1sNCAx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 配置路径 - Colab 版本\n",
        "BASE_DIR = input_dir\n",
        "INPUT_JSON_PATH = BASE_DIR / \"all_pdf_page_chunks.json\"  # 注意文件名\n",
        "OUTPUT_DIR = drive_root / \"knowledge_base\"\n",
        "FINAL_KB_PATH = OUTPUT_DIR / \"multimodal_knowledge_base.pkl\"\n",
        "CHUNKS_JSON_PATH = OUTPUT_DIR / \"processed_chunks.json\"\n",
        "\n",
        "# 创建输出目录\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# CLIP模型配置\n",
        "CLIP_MODEL_NAME = \"openai/clip-vit-base-patch32\"  # ~600MB，免费使用\n",
        "BATCH_SIZE = 16  # 根据GPU内存调整\n",
        "MAX_TEXT_LENGTH = 77  # CLIP文本输入限制\n",
        "\n",
        "print(f\"输入JSON文件: {INPUT_JSON_PATH}\")\n",
        "print(f\"输出目录: {OUTPUT_DIR}\")\n",
        "print(f\"最终知识库: {FINAL_KB_PATH}\")\n",
        "print(f\"CLIP模型: {CLIP_MODEL_NAME}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E9EBOHzEB8_",
        "outputId": "7c914313-ed7f-4810-80a6-10eb048ebe93"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "输入JSON文件: /content/drive/MyDrive/RAG_处理结果/all_pdf_page_chunks.json\n",
            "输出目录: /content/drive/MyDrive/knowledge_base\n",
            "最终知识库: /content/drive/MyDrive/knowledge_base/multimodal_knowledge_base.pkl\n",
            "CLIP模型: openai/clip-vit-base-patch32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "luNT_spLEBrF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 加载和初始化CLIP模型"
      ],
      "metadata": {
        "id": "FM0PWOOgE56i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 加载CLIP模型和处理器\n",
        "print(\"正在加载CLIP模型和处理器...\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"使用设备: {device}\")\n",
        "\n",
        "try:\n",
        "  clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
        "  clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "  clip_model.eval()\n",
        "  print(\"CLIP模型和处理器加载成功！\")\n",
        "except Exception as e:\n",
        "  print(f\"加载CLIP模型和处理器时出错: {e}\")\n",
        "  raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "365a4d6b9a4a414f87a7742d19c6a2ae",
            "59b0b16eb92046878b3fa00e7e4e8bfc",
            "f32fc92bb15547fea3d87d5bbfe66126",
            "19b87267b5734d49869a97eec665ea42",
            "55c4e12af789473c8ef61e305007ddf9",
            "597a23d6b73647a6a63b2b25f94754d9",
            "d84f63a3c58b43ce8cb5cb4ea3caa435",
            "00020c7fd27944beadf6fe8f85232f48",
            "88b99099199f4e4eb5ffc57a0e1e26fb",
            "dfd0b5c3ffd4454b8aec0bb74b066ec8",
            "93d084695dca434bafa3d40793c2aa4f"
          ]
        },
        "id": "uQFD_cISFAd7",
        "outputId": "c936ff14-8aa4-4c62-9bb5-ca1661613ae1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正在加载CLIP模型和处理器...\n",
            "使用设备: cpu\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "365a4d6b9a4a414f87a7742d19c6a2ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLIP模型和处理器加载成功！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 数据加载和预处理"
      ],
      "metadata": {
        "id": "Ak3zyzapF06f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 加载阶段一的JSON数据\n",
        "print(\"正在加载阶段一的JSON数据...\")\n",
        "with open(INPUT_JSON_PATH, 'r', encoding='utf-8') as f:\n",
        "    raw_content_list = json.load(f)\n",
        "print(f\"加载完成，共 {len(raw_content_list)} 个内容块\")\n",
        "\n",
        "# 数据结构分析\n",
        "type_counts = {}\n",
        "for item in raw_content_list:\n",
        "    item_type = item.get('type', 'unknown')\n",
        "    type_counts[item_type] = type_counts.get(item_type, 0) + 1\n",
        "\n",
        "print(\"\\n📊 内容类型统计:\")\n",
        "for item_type, count in type_counts.items():\n",
        "    print(f\"  {item_type}: {count} 个\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voMT3K2EF21u",
        "outputId": "a03fcb73-d230-41c9-9cd9-08cb4328908b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正在加载阶段一的JSON数据...\n",
            "加载完成，共 4294 个内容块\n",
            "\n",
            "📊 内容类型统计:\n",
            "  unknown: 4294 个\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 清洗和结构化原始数据，生成标准化的chunk格式"
      ],
      "metadata": {
        "id": "bxLqNrO-Gnhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 检查原始数据的结构\n",
        "print(\"检查前几个数据项的结构:\")\n",
        "for i in range(min(3, len(raw_content_list))):\n",
        "    print(f\"\\n第{i+1}个数据项:\")\n",
        "    print(f\"  类型: {type(raw_content_list[i])}\")\n",
        "    if isinstance(raw_content_list[i], dict):\n",
        "        print(f\"  键: {list(raw_content_list[i].keys())}\")\n",
        "        for key, value in raw_content_list[i].items():\n",
        "            if isinstance(value, str) and len(value) > 100:\n",
        "                print(f\"  {key}: {value[:100]}...\")\n",
        "            else:\n",
        "                print(f\"  {key}: {value}\")\n",
        "    else:\n",
        "        print(f\"  内容: {raw_content_list[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6XptU-EMLuy",
        "outputId": "2e732579-c660-4384-b847-0e9d10bcb9e2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "检查前几个数据项的结构:\n",
            "\n",
            "第1个数据项:\n",
            "  类型: <class 'dict'>\n",
            "  键: ['id', 'content', 'metadata']\n",
            "  id: 伊利股份-大象起舞龙头远航-2020072627页_page_0\n",
            "  content: 请仔细阅读本报告末页声明 \n",
            "证券研究报告 | 首次覆盖报告 \n",
            "2020 年07 月26 日 \n",
            "伊利股份（600887.SH） \n",
            "大象起舞，龙头远航 \n",
            "看历史：步步为营，终成乳业龙头。公司创始于1993...\n",
            "  metadata: {'filename': '伊利股份-大象起舞龙头远航-2020072627页', 'page': 0, 'source': 'pymupdf', 'total_pages': 27}\n",
            "\n",
            "第2个数据项:\n",
            "  类型: <class 'dict'>\n",
            "  键: ['id', 'content', 'metadata']\n",
            "  id: 伊利股份-大象起舞龙头远航-2020072627页_page_1\n",
            "  content: 2020 年07 月26 日 \n",
            "P.2                                   请仔细阅读本报告末页声明 \n",
            " \n",
            "财务报表和主要财务比率 \n",
            "  \n",
            "资产负债表（百万元）  \n",
            " ...\n",
            "  metadata: {'filename': '伊利股份-大象起舞龙头远航-2020072627页', 'page': 1, 'source': 'pymupdf', 'total_pages': 27}\n",
            "\n",
            "第3个数据项:\n",
            "  类型: <class 'dict'>\n",
            "  键: ['id', 'content', 'metadata']\n",
            "  id: 伊利股份-大象起舞龙头远航-2020072627页_page_2\n",
            "  content: qRtMoOoRpQmOuMqPqMtMsRaQ8QbRoMrRmOoOfQqQtMeRnPoR6MqQzQMYoNoOMYmQrO\n",
            " 2020 年07 月26 日 \n",
            "P.3             ...\n",
            "  metadata: {'filename': '伊利股份-大象起舞龙头远航-2020072627页', 'page': 2, 'source': 'pymupdf', 'total_pages': 27}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_and_structure_data(raw_data: List[Dict]) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    清洗和结构化原始数据，生成标准化的chunk格式\n",
        "    \"\"\"\n",
        "    processed_chunks = []\n",
        "\n",
        "    for i, item in enumerate(tqdm(raw_data, desc=\"数据清洗\")):\n",
        "        try:\n",
        "            # 提取基本信息\n",
        "            content_text = item.get('content', '')\n",
        "            item_id = item.get('id', f'chunk_{i:06d}')\n",
        "            metadata = item.get('metadata', {})\n",
        "\n",
        "            #从metadata中提取信息\n",
        "            source_file = metadata.get('filename','unknow')\n",
        "            page_num = metadata.get('page', 0)\n",
        "\n",
        "\n",
        "            # 处理不同类型的内容\n",
        "            chunk = {\n",
        "                'id': item_id,\n",
        "                'content': content_text.strip() if content_text else '',\n",
        "                'type': 'text',\n",
        "                'metadata': {\n",
        "                    'source_file': source_file,\n",
        "                    'page_num': page_num,\n",
        "                    'original_index': i,\n",
        "                    'total_pages': metadata.get('total_pages', 0)\n",
        "                }\n",
        "            }\n",
        "\n",
        "\n",
        "            # 只保留有内容的chunk\n",
        "            if chunk['content'].strip():\n",
        "                processed_chunks.append(chunk)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"处理第{i}个内容块时出错: {e}\")\n",
        "            continue\n",
        "\n",
        "    return processed_chunks"
      ],
      "metadata": {
        "id": "LAqPWyXMGr_P"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 执行数据清洗\n",
        "processed_chunks = clean_and_structure_data(raw_content_list)\n",
        "print(f\"\\n✅ 数据清洗完成，有效chunk数: {len(processed_chunks)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGFCEyxrL--E",
        "outputId": "10f5ffaf-6807-4211-ae98-11d750bd745e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "数据清洗: 100%|██████████| 4294/4294 [00:00<00:00, 273617.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ 数据清洗完成，有效chunk数: 4294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. CLIP向量化函数"
      ],
      "metadata": {
        "id": "Suc_qQMLKGR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_text_with_clip(texts: List[str], batch_size: int = BATCH_SIZE) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    使用CLIP对文本进行批量编码\n",
        "    \"\"\"\n",
        "    all_embeddings = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(texts), batch_size), desc=\"文本向量化\"):\n",
        "            batch_texts = texts[i:i + batch_size]\n",
        "\n",
        "            # 截断过长的文本\n",
        "            truncated_texts = [text[:500] for text in batch_texts]  # 保守截断\n",
        "\n",
        "            try:\n",
        "                # CLIP文本编码\n",
        "                inputs = clip_processor(text=truncated_texts, return_tensors=\"pt\",\n",
        "                                      padding=True, truncation=True, max_length=MAX_TEXT_LENGTH)\n",
        "                inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "                text_features = clip_model.get_text_features(**inputs)\n",
        "                text_features = text_features / text_features.norm(dim=-1, keepdim=True)  # 归一化\n",
        "\n",
        "                all_embeddings.append(text_features.cpu().numpy())\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"文本编码出错: {e}\")\n",
        "                # 使用零向量作为fallback\n",
        "                fallback_embedding = np.zeros((len(batch_texts), 512))\n",
        "                all_embeddings.append(fallback_embedding)\n",
        "\n",
        "    return np.vstack(all_embeddings)\n",
        "\n",
        "def encode_image_with_clip(image_data: str) -> Optional[np.ndarray]:\n",
        "    \"\"\"\n",
        "    使用CLIP对单个图像进行编码\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 解码base64图像\n",
        "        if image_data.startswith('data:image'):\n",
        "            image_data = image_data.split(',')[1]\n",
        "\n",
        "        image_bytes = base64.b64decode(image_data)\n",
        "        image = Image.open(BytesIO(image_bytes)).convert('RGB')\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs = clip_processor(images=image, return_tensors=\"pt\")\n",
        "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "            image_features = clip_model.get_image_features(**inputs)\n",
        "            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            return image_features.cpu().numpy().flatten()\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"图像编码出错: {e}\")\n",
        "        return None\n",
        "\n",
        "print(\"✅ CLIP向量化函数定义完成\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPG59-xWKIWu",
        "outputId": "00ffed40-6ba7-4c8b-9d20-8d8ade29c3cb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CLIP向量化函数定义完成\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. 批量向量化处理"
      ],
      "metadata": {
        "id": "GeJjK6DBKStZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 分离文本和图像内容\n",
        "text_chunks = []\n",
        "image_chunks = []\n",
        "\n",
        "for chunk in processed_chunks:\n",
        "    if chunk.get('has_image', False):\n",
        "        image_chunks.append(chunk)\n",
        "    else:\n",
        "        text_chunks.append(chunk)\n",
        "\n",
        "print(f\"📝 纯文本chunk: {len(text_chunks)} 个\")\n",
        "print(f\"🖼️ 包含图像chunk: {len(image_chunks)} 个\")\n",
        "print(f\"📊 总计: {len(processed_chunks)} 个\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDk1zvEAKUQr",
        "outputId": "1e7c2625-cfe2-46f4-c63c-15310ff3869c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📝 纯文本chunk: 4294 个\n",
            "🖼️ 包含图像chunk: 0 个\n",
            "📊 总计: 4294 个\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 处理纯文本chunk\n",
        "print(\"\\n🔄 开始处理纯文本内容...\")\n",
        "if text_chunks:\n",
        "    text_contents = [chunk['content'] for chunk in text_chunks]\n",
        "    text_embeddings = encode_text_with_clip(text_contents)\n",
        "\n",
        "    # 将向量添加到chunk中\n",
        "    for i, chunk in enumerate(text_chunks):\n",
        "        chunk['vector'] = text_embeddings[i].tolist()\n",
        "        chunk['vector_type'] = 'text'\n",
        "\n",
        "    print(f\"✅ 文本向量化完成: {len(text_chunks)} 个\")\n",
        "else:\n",
        "    print(\"⚠️ 没有纯文本内容需要处理\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRg020qwKYQv",
        "outputId": "91ac2a1d-7614-4c4f-d14b-f33fce345d85"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 开始处理纯文本内容...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "文本向量化: 100%|██████████| 269/269 [08:40<00:00,  1.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 文本向量化完成: 4294 个\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 处理图像chunk\n",
        "print(\"\\n🔄 开始处理图像内容...\")\n",
        "successful_images = 0\n",
        "failed_images = 0\n",
        "\n",
        "for chunk in tqdm(image_chunks, desc=\"图像向量化\"):\n",
        "    image_data = chunk.get('image_data')\n",
        "    if image_data:\n",
        "        image_vector = encode_image_with_clip(image_data)\n",
        "        if image_vector is not None:\n",
        "            chunk['vector'] = image_vector.tolist()\n",
        "            chunk['vector_type'] = 'image'\n",
        "            successful_images += 1\n",
        "        else:\n",
        "            # 图像处理失败，使用文本向量作为fallback\n",
        "            text_vector = encode_text_with_clip([chunk['content']])\n",
        "            chunk['vector'] = text_vector[0].tolist()\n",
        "            chunk['vector_type'] = 'text_fallback'\n",
        "            failed_images += 1\n",
        "    else:\n",
        "        # 没有图像数据，使用文本向量\n",
        "        text_vector = encode_text_with_clip([chunk['content']])\n",
        "        chunk['vector'] = text_vector[0].tolist()\n",
        "        chunk['vector_type'] = 'text_fallback'\n",
        "        failed_images += 1\n",
        "\n",
        "print(f\"✅ 图像向量化完成:\")\n",
        "print(f\"  成功处理图像: {successful_images} 个\")\n",
        "print(f\"  使用文本fallback: {failed_images} 个\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wpIjRbcKdDX",
        "outputId": "9204b377-372a-4e01-9813-44a6383653bf"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 开始处理图像内容...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "图像向量化: 0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 图像向量化完成:\n",
            "  成功处理图像: 0 个\n",
            "  使用文本fallback: 0 个\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. 构建最终知识库"
      ],
      "metadata": {
        "id": "qLL9q7zAQLks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 合并所有处理后的chunk\n",
        "final_chunks = text_chunks + image_chunks\n",
        "# 验证所有chunk都有向量\n",
        "chunks_with_vectors = [chunk for chunk in final_chunks if 'vector' in chunk]\n",
        "print(f\"\\n📊 最终统计:\")\n",
        "print(f\"  总chunk数: {len(final_chunks)}\")\n",
        "print(f\"  有向量的chunk: {len(chunks_with_vectors)}\")\n",
        "print(f\"  向量维度: {len(chunks_with_vectors[0]['vector']) if chunks_with_vectors else 'N/A'}\")\n",
        "\n",
        "# 统计向量类型\n",
        "vector_type_counts = {}\n",
        "for chunk in chunks_with_vectors:\n",
        "    vtype = chunk.get('vector_type', 'unknown')\n",
        "    vector_type_counts[vtype] = vector_type_counts.get(vtype, 0) + 1\n",
        "\n",
        "print(\"\\n🏷️ 向量类型统计:\")\n",
        "for vtype, count in vector_type_counts.items():\n",
        "    print(f\"  {vtype}: {count} 个\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V4HYZ1DQNkC",
        "outputId": "0dd11c20-1892-4c6a-8ca1-f58d9b783dfb"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 最终统计:\n",
            "  总chunk数: 4294\n",
            "  有向量的chunk: 4294\n",
            "  向量维度: 512\n",
            "\n",
            "🏷️ 向量类型统计:\n",
            "  text: 4294 个\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 构建知识库数据结构\n",
        "knowledge_base = {\n",
        "    'metadata': {\n",
        "        'version': '1.0',\n",
        "        'created_at': str(pd.Timestamp.now()),\n",
        "        'clip_model': CLIP_MODEL_NAME,\n",
        "        'total_chunks': len(chunks_with_vectors),\n",
        "        'vector_dimension': len(chunks_with_vectors[0]['vector']) if chunks_with_vectors else 0,\n",
        "        'vector_type_counts': vector_type_counts\n",
        "    },\n",
        "    'chunks': chunks_with_vectors\n",
        "}\n",
        "\n",
        "print(f\"\\n🏗️ 知识库构建完成\")\n",
        "print(f\"  元数据: {len(knowledge_base['metadata'])} 项\")\n",
        "print(f\"  数据块: {len(knowledge_base['chunks'])} 个\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUvWtscIQsRV",
        "outputId": "7d6f77c9-7bfb-46a3-c3b8-2b42a5ce532a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🏗️ 知识库构建完成\n",
            "  元数据: 6 项\n",
            "  数据块: 4294 个\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. 持久化保存"
      ],
      "metadata": {
        "id": "RqeIcFP3Q-1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 保存为JSON格式（便于查看和调试）\n",
        "print(\"💾 保存JSON格式...\")\n",
        "with open(CHUNKS_JSON_PATH, 'w', encoding='utf-8') as f:\n",
        "    json.dump(knowledge_base, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "json_size = CHUNKS_JSON_PATH.stat().st_size / 1024 / 1024\n",
        "print(f\"✅ JSON文件保存完成: {CHUNKS_JSON_PATH} ({json_size:.2f} MB)\")\n",
        "\n",
        "# 保存为Pickle格式（更高效的加载）\n",
        "print(\"💾 保存Pickle格式...\")\n",
        "with open(FINAL_KB_PATH, 'wb') as f:\n",
        "    pickle.dump(knowledge_base, f)\n",
        "\n",
        "pickle_size = FINAL_KB_PATH.stat().st_size / 1024 / 1024\n",
        "print(f\"✅ Pickle文件保存完成: {FINAL_KB_PATH} ({pickle_size:.2f} MB)\")\n",
        "\n",
        "print(f\"\\n📁 知识库文件:\")\n",
        "print(f\"  JSON格式: {CHUNKS_JSON_PATH} ({json_size:.2f} MB)\")\n",
        "print(f\"  Pickle格式: {FINAL_KB_PATH} ({pickle_size:.2f} MB)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECKYMkQGRATy",
        "outputId": "fe47075e-55fc-462f-dc90-c94ff368da02"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 保存JSON格式...\n",
            "✅ JSON文件保存完成: /content/drive/MyDrive/knowledge_base/processed_chunks.json (75.29 MB)\n",
            "💾 保存Pickle格式...\n",
            "✅ Pickle文件保存完成: /content/drive/MyDrive/knowledge_base/multimodal_knowledge_base.pkl (29.48 MB)\n",
            "\n",
            "📁 知识库文件:\n",
            "  JSON格式: /content/drive/MyDrive/knowledge_base/processed_chunks.json (75.29 MB)\n",
            "  Pickle格式: /content/drive/MyDrive/knowledge_base/multimodal_knowledge_base.pkl (29.48 MB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. **知识库质量验证**"
      ],
      "metadata": {
        "id": "gbG5P66NRfIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 简单的向量搜索测试\n",
        "def cosine_similarity(v1, v2):\n",
        "    \"\"\"计算余弦相似度\"\"\"\n",
        "    v1, v2 = np.array(v1), np.array(v2)\n",
        "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
        "\n",
        "def simple_search(query_text: str, top_k: int = 3):\n",
        "    \"\"\"简单的向量搜索测试\"\"\"\n",
        "    # 对查询进行向量化\n",
        "    query_vector = encode_text_with_clip([query_text])[0]\n",
        "\n",
        "    # 计算与所有chunk的相似度\n",
        "    similarities = []\n",
        "    for chunk in chunks_with_vectors:\n",
        "        sim = cosine_similarity(query_vector, chunk['vector'])\n",
        "        similarities.append((sim, chunk))\n",
        "\n",
        "    # 排序并返回top_k\n",
        "    similarities.sort(key=lambda x: x[0], reverse=True)\n",
        "    return similarities[:top_k]\n",
        "\n",
        "# 测试搜索功能\n",
        "test_queries = [\n",
        "    \"财务报表\",\n",
        "    \"营业收入\",\n",
        "    \"资产负债表\"\n",
        "]\n",
        "\n",
        "print(\"\\n🔍 知识库搜索测试:\")\n",
        "for query in test_queries:\n",
        "    print(f\"\\n查询: '{query}'\")\n",
        "    results = simple_search(query, top_k=2)\n",
        "    for i, (score, chunk) in enumerate(results, 1):\n",
        "        content_preview = chunk['content'][:100] + \"...\" if len(chunk['content']) > 100 else chunk['content']\n",
        "        print(f\"  {i}. 相似度: {score:.3f} | {content_preview}\")\n",
        "\n",
        "print(\"\\n✅ 搜索测试完成！\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXzGQ374RhEv",
        "outputId": "d6cd0d22-86e7-45c5-b3e2-8b8690e13b1c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 知识库搜索测试:\n",
            "\n",
            "查询: '财务报表'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "文本向量化: 100%|██████████| 1/1 [00:00<00:00, 10.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  1. 相似度: 0.959 | 证券研究报告\n",
            "  2. 相似度: 0.955 | 证券研究报告\n",
            "附表：财务预测与估值\n",
            "资产负债表（百万元）\n",
            "2023\n",
            "2024\n",
            "2025E\n",
            "2026E\n",
            "2027E\n",
            "利润表（百万元）\n",
            "2023\n",
            "2024\n",
            "2025E\n",
            "2026E\n",
            "2027E\n",
            "现金及现金等...\n",
            "\n",
            "查询: '营业收入'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "文本向量化: 100%|██████████| 1/1 [00:00<00:00, 12.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  1. 相似度: 0.966 | 一、\n",
            "营销中心：负责市场营销业务，进行市场开拓、销售业务、品牌推广及产品管理等工作，由营销副总经理负责管理。营销中心下设重客部、经\n",
            "销商客户部、渠道拓展部、行销部及产品管理部等。公司对每类大B客户都...\n",
            "  2. 相似度: 0.962 | -53-\n",
            "附录：财务预测表\n",
            "\n",
            "查询: '资产负债表'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "文本向量化: 100%|██████████| 1/1 [00:00<00:00, 13.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  1. 相似度: 0.973 | 证券研究报告\n",
            "  2. 相似度: 0.965 | 1 投资逻辑 \n",
            "市场担心速冻米面行业的竞争会加剧。我们认为：连锁餐饮供应体系相对封闭，进入壁垒\n",
            "较高，公司具有先发优势。千味央厨对餐饮场景的理解深刻，公司始终深入一线，研究餐\n",
            "饮应用场景的痛点和需求。...\n",
            "\n",
            "✅ 搜索测试完成！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. 生成部署配置文件"
      ],
      "metadata": {
        "id": "-kCWzvXASEFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 生成部署所需的配置信息\n",
        "deployment_config = {\n",
        "    \"knowledge_base_path\": str(FINAL_KB_PATH.name),  # 相对路径\n",
        "    \"clip_model_name\": CLIP_MODEL_NAME,\n",
        "    \"vector_dimension\": len(chunks_with_vectors[0]['vector']) if chunks_with_vectors else 512,\n",
        "    \"total_chunks\": len(chunks_with_vectors),\n",
        "    \"deployment_ready\": True,\n",
        "    \"required_packages\": [\n",
        "        \"transformers\",\n",
        "        \"torch\",\n",
        "        \"numpy\",\n",
        "        \"gradio\",\n",
        "        \"pillow\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "config_path = OUTPUT_DIR / \"deployment_config.json\"\n",
        "with open(config_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(deployment_config, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"\\n⚙️ 部署配置文件已生成: {config_path}\")\n",
        "print(\"\\n🎉 阶段二完成！知识库已构建完成，可以进入阶段三进行检索调试。\")\n",
        "print(\"\\n📋 下一步:\")\n",
        "print(\"  1. 运行阶段三Notebook进行检索逻辑调试\")\n",
        "print(\"  2. 完成后即可部署到HuggingFace Spaces\")\n",
        "print(f\"  3. 记得将 {FINAL_KB_PATH.name} 文件上传到Spaces项目中\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_J9hE-XSJv3",
        "outputId": "a8a26f49-3685-4a98-9c3b-b419589c6601"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⚙️ 部署配置文件已生成: /content/drive/MyDrive/knowledge_base/deployment_config.json\n",
            "\n",
            "🎉 阶段二完成！知识库已构建完成，可以进入阶段三进行检索调试。\n",
            "\n",
            "📋 下一步:\n",
            "  1. 运行阶段三Notebook进行检索逻辑调试\n",
            "  2. 完成后即可部署到HuggingFace Spaces\n",
            "  3. 记得将 multimodal_knowledge_base.pkl 文件上传到Spaces项目中\n"
          ]
        }
      ]
    }
  ]
}